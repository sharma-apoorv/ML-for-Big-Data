{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"friendship-recommendation_2","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyObyH3P+2YqC3l+oIDNJbOh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5h7dOSGA_Gwy"},"source":["Write a Spark program that implements a simple “People You Might Know” social network friendship recommendation algorithm. The key idea is that if two people have a lot of mutual friends, then the system should recommend that they connect with each other.\n"]},{"cell_type":"code","metadata":{"id":"9EtmNhpN-77D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618439030676,"user_tz":420,"elapsed":5064,"user":{"displayName":"Apoorv Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjO0ftIG0bDuKlCjMrdHvLDCwUreEcBf3lAT5gp=s64","userId":"09578640252499880764"}},"outputId":"8109364d-4c8a-4383-86e6-ef3a8fa631fc"},"source":["!pip install pyspark\n","!apt install openjdk-8-jdk-headless -qq\n","\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.1)\n","Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n","openjdk-8-jdk-headless is already the newest version (8u282-b08-0ubuntu1~18.04).\n","0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PWY6a1bScyB3"},"source":["# Import PyDrive and associated libraries.\n","# This only needs to be done once per notebook.\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once per notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Download a file based on its file ID.\n","#\n","# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n","file_id = '1QQ-EAUEiziAOMq8b-jWfbjKTBlUL4ZRQ'\n","downloaded = drive.CreateFile({'id': file_id})\n","downloaded.GetContentFile('soc-LiveJournal1Adj.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-7tu1C4ZCfZ8"},"source":["from pyspark import SparkContext, SparkConf\n","from itertools import combinations"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cDR_00TH3LBN"},"source":["We first create a Spark context. The Spark context is the main entry point for Spark functionality. A SparkContext represents the connection to a Spark cluster, and can be used to create RDDs, accumulators and broadcast variables on that cluster.\n"]},{"cell_type":"code","metadata":{"id":"q4jKSvvFCmAn"},"source":["# create the session\n","conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n","\n","# create the context\n","sc = SparkContext(conf=conf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0nSTVmm3CrMM"},"source":["# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","# !unzip ngrok-stable-linux-amd64.zip\n","\n","# get_ipython().system_raw('./ngrok http 4050 &')\n","# !curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nBKy1qjM3u3U"},"source":["We now read the file in using the `textFile()` function provided as part of the Spark API. The function will read a text file from a local file system (available on all nodes) and return it as an RDD of strings.\n","\n","Thus the variable `file_rdd` will be an RDD with the following underlying format:\n","\n","```\n","[\n","    '1\\t2,3,4,5...',\n","    '2\\t1,3,4,5...',\n","    '7\\t2,3,5,23...',\n","    ...\n","]\n","```"]},{"cell_type":"code","metadata":{"id":"PYdllNLtC0f9"},"source":["Q1_FILE_PATH = 'soc-LiveJournal1Adj.txt'\n","file_rdd = sc.textFile(Q1_FILE_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ioMj-b_i4l1R"},"source":["We now parse each string contained in the `file_rdd` variable. A format relevant that we can use later on will be in the form of keys and values. Thus, we will set the following keys and values for each line we are parsing:\n","\n","**key** : The user id of the person\n","\n","**value** : The list of user ids of their friends\n","\n","As a result, we should obtain the following structure in the `parsed_file_rdd` variable:\n","\n","```\n","[\n","    (1, [2, 3, 4, 5, ...]),\n","    (2, [1, 3, 4, 5, ...]),\n","    (7, [2, 3, 5, 23, ...]),\n","    ...\n","]\n","```"]},{"cell_type":"code","metadata":{"id":"J06FXQbPEKJ2"},"source":["def parse_file_line(line):\n","    line = line.strip()\n","\n","    try:\n","        user, friends_str = line.split('\\t')\n","    except ValueError:\n","        user, friends_str = line, \"\"\n","\n","    # convert the user_id to an int\n","    user = int(user)\n","\n","    friends_list = []\n","    if friends_str:\n","        # ensure all elements are ints\n","        friends_list = sorted(list(map(int, friends_str.split(','))))\n","\n","    return ((user, friends_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GKI-J8jhTn85"},"source":["# parse the file and obtain into a relavant format for Spark to process\n","parsed_file_rdd = file_rdd.map(parse_file_line)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EhJaobL95s8j"},"source":["Now that we have a format that we can work with, we need to encode some usefule information so that we can find the mutual friends and eventually reccomend users some new friends. Lets take the following entry as an example:\n","\n","`(1, [2, 3, 4, 5])`\n","\n","Here we know 1 has the following friends: 2, 3, 4, 5. This information is not very relevant, since we are trying to find **mutual friends**. However, we know that each pair of friends in the list have user_id 1 as a mutual friend. To further clarify, The following pairs (2,3), (2,4), (2,5), ... all have 1 as their mutual friend. This information is useful for us.\n","\n","We will want our RDD to have the following structure:\n","\n","```\n","[\n","    (user_id_1, user_id_2) : 0, \n","    (user_id_3, user_id_4) : 1,\n","    ...\n","]\n","```\n","\n","Here the `0` indicates that `user_id_1` and `user_id_2` are **direct friends**. \n","\n","The `1` indicates that `user_id_3` and `user_id_4` have some **mutual friend** in common."]},{"cell_type":"code","metadata":{"id":"huTSUOM2TtVn"},"source":["def map_friend_tuples(friends_tuple):\n","    user, friends = friends_tuple\n","    num_friends = len(friends)\n","\n","    IS_FRIEND = float('-inf')\n","    HAS_MUTUAL_FRIEND = 1 # we set this to 1, as we will sum up the values later\n","\n","    friends_tuple_list = []\n","\n","    for friend_id in friends:\n","        friend_key = tuple(sorted([user, friend_id]))\n","        friends_tuple_list.append( (friend_key, IS_FRIEND) ) # encode the user and current friend_id are friends\n","    \n","    mutual_friend_list = combinations(friends, 2)\n","    for f1, f2 in mutual_friend_list:\n","        mutual_friend_key = tuple(sorted([f1, f2]))\n","        friends_tuple_list.append( (tuple(mutual_friend_key), HAS_MUTUAL_FRIEND) )\n","    \n","    return friends_tuple_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DGh4Dkj2UIcK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618439038563,"user_tz":420,"elapsed":12833,"user":{"displayName":"Apoorv Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjO0ftIG0bDuKlCjMrdHvLDCwUreEcBf3lAT5gp=s64","userId":"09578640252499880764"}},"outputId":"d7a2d221-2155-40b1-b9e5-4711b4c7c3a9"},"source":["friends_rdd = parsed_file_rdd.flatMap(map_friend_tuples)\n","friends_rdd.cache()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PythonRDD[2] at RDD at PythonRDD.scala:53"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"BkB3NlDI7_G0"},"source":["We can now add all the values for each key and obtain how many mutual friends each pair has. The underlying structure after the execution will be as follows:\n","\n","```\n","[\n","    (user_id_1, user_id_2) : 0, \n","    (user_id_3, user_id_4) : 14,\n","    (user_id_5, user_id_6) : 4,\n","    (user_id_7, user_id_8) : 7,\n","    (user_id_9, user_id_10) : 9,\n","    (user_id_11, user_id_12) : 323,\n","    ...\n","]\n","```"]},{"cell_type":"code","metadata":{"id":"rlVtqR0hZuQN"},"source":["mutual_friends_count_rdd = friends_rdd.reduceByKey(lambda a, b: a + b).filter(lambda x: x[1] > 0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x2obdHjI8pAa"},"source":["We again need to restructure the format of our RDD. At this point we know how many friends each pair has. However, we want to find out for each user what which second user has the most number of friends. As a result we will restructure to the following format:\n","\n","```\n","[\n","    (user_id_1, user_id_2),  0, --> (user_id_1, (user_id_2, 0)),\n","    (user_id_3, user_id_4), 14, --> (user_id_3, (user_id_4, 14))\n","    ...\n","]\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"r3JQjNxAhF16"},"source":["mutual_friends_count_remap_rdd = mutual_friends_count_rdd.flatMap(lambda info : [(info[0][0], (info[0][1], info[1])), (info[0][1], (info[0][0], info[1]))] )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YHwGLZ7a3lHS"},"source":["Now that the key has been transformed to a single variable that is not unique across the elements in the list, we can group up the keys and sort based on the number of mutual friends. \n","\n","We first apply a `groupByKey` operation and obtain a list of values for that particular user. This may look as follows:\n","\n","(friend_id, number_of_mutual_friends)\n","```\n","[(3, 45), (10, 278), (3, 75), ...]\n","```\n","\n","The above list shows all the how many mutual friends a user has with another user. We then sort based on the `number_of_mutual_friends` in a **descending** order and then sort based on the `friend_id` in an ascending order, to break any ties. For the purpose of the algorithm, we will only show the top 10 reccomended friends. \n","\n","Once sorted, we can then just return a list of friends and get rid of the counts. "]},{"cell_type":"code","metadata":{"id":"nYBG7rZe-meA"},"source":["def get_reccomendations(mutual_friend_count_list, num_reccomendations=10):\n","\n","    top_reccomendation_pairs = sorted( mutual_friend_count_list, key = lambda pair: (-pair[1], pair[0]) )[:num_reccomendations]\n","\n","    reccomendations = [pair[0] for pair in top_reccomendation_pairs]\n","\n","    return reccomendations"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6du4wtt-F7Y"},"source":["friend_reccomendations_rdd = mutual_friends_count_remap_rdd.groupByKey().mapValues(get_reccomendations)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YHdhHCqIB8D4"},"source":["reccomendations = friend_reccomendations_rdd.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gnzHcSh-5VVX"},"source":["We now sort based on the user id (each key) for uniformness. "]},{"cell_type":"code","metadata":{"id":"VH-tKrIhC3se"},"source":["reccomendations.sort(key=lambda pair: pair[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XFMuICWq5gyY"},"source":["We finally write the result to an output file, in a similar format as the input file"]},{"cell_type":"code","metadata":{"id":"vWweQGBI5gZ-"},"source":["def write_reccomendations_to_file(reccomendations_list):\n","\n","    lines = []\n","    for user, friends_recc in reccomendations_list:\n","        user_str = str(user)\n","        friends_str = ','.join(map(str, friends_recc)) \n","\n","        if friends_str:\n","            line = user_str + '\\t' + friends_str + '\\n'\n","        else:\n","            line = user_str + '\\t' + '\\n'\n","\n","        lines.append(line)\n","    \n","    with open('friend_reccomendations.txt', 'w') as f:\n","        f.writelines(lines)\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Jl0yZ8M7W2m"},"source":["write_reccomendations_to_file(reccomendations)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ek8C7ffEGZ8f","executionInfo":{"status":"ok","timestamp":1618439291552,"user_tz":420,"elapsed":265742,"user":{"displayName":"Apoorv Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjO0ftIG0bDuKlCjMrdHvLDCwUreEcBf3lAT5gp=s64","userId":"09578640252499880764"}},"outputId":"3875abcb-1e5a-4e2e-8ee1-795d8b8ec01f"},"source":["submission_user_id_list = set([924, 8941, 8942, 9019, 9020, 9021, 9022, 9990, 9992, 9993])\n","\n","output_list = []\n","for user, friends_recc in reccomendations:\n","    if user in submission_user_id_list:\n","        output_list.append((user, friends_recc))\n","\n","output_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(924, [439, 2409, 6995, 11860, 15416, 43748, 45881]),\n"," (8941, [8943, 8944, 8940]),\n"," (8942, [8939, 8940, 8943, 8944]),\n"," (9019, [9022, 317, 9023]),\n"," (9020, [9021, 9016, 9017, 9022, 317, 9023]),\n"," (9021, [9020, 9016, 9017, 9022, 317, 9023]),\n"," (9022, [9019, 9020, 9021, 317, 9016, 9017, 9023]),\n"," (9990, [13134, 13478, 13877, 34299, 34485, 34642, 37941]),\n"," (9992, [9987, 9989, 35667, 9991]),\n"," (9993, [9991, 13134, 13478, 13877, 34299, 34485, 34642, 37941])]"]},"metadata":{"tags":[]},"execution_count":21}]}]}